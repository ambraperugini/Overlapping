


\documentclass[twocolumn]{article}
%\documentclass[10pt]{article}
\usepackage{color}
\usepackage[italian,english]{babel}
\usepackage{hyperref}
\usepackage[margin=2cm]{geometry}
\usepackage{bm}
\usepackage{tikz}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{apacite}
\usepackage[bottom]{footmisc} 

\newcommand\BibTeX{{\rmfamily B\kern-.05em \textsc{i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{Schunk}
\begin{Sinput}
> library(knitr)
> options(digits=3)
> opts_chunk$set(fig.width=3, fig.height=3, dev="tikz",fig.align='center',echo=FALSE,results="hide",comment=NA,prompt=FALSE,warning=FALSE, cache = TRUE)
\end{Sinput}
\end{Schunk}
\usepackage[colorlinks,bookmarksopen,bookmarksnumbered,citecolor=red,urlcolor=red]{hyperref}
\usepackage{float}
\floatstyle{boxed}
\newfloat{program}{btp}{lop}
\floatname{program}{Box}
\usepackage{mdframed}
\definecolor{boxcol}{RGB}{213,226,238}
\newmdenv[linecolor=boxcol,backgroundcolor=boxcol]{comments}


\begin{Schunk}
\begin{Sinput}
> rm(list=ls())
> main <- "/Users/ambraperugini/Library/CloudStorage/OneDrive-UniversitàdegliStudidiPadova/Lavoro/Overlapping/"
> #main <- "/home/bayes/lavori/overpermutation/"
> datadir <- paste0(main,"data/")
> # KUtils::pulizia(paste(main,"knitr/",sep=""), c(".Rnw",".bib","pdf"),TRUE)
\end{Sinput}
\end{Schunk}


\usepackage{Sweave}
\begin{document}
\input{Articolo_overlapping_01-concordance}

\title{\textbf{\textit{How do my distributions differ?} \\ Significance testing for the Overlapping Index \\ using Permutation Test}}
\author{Ambra Perugini $^1$, Giulia Calignano $^1$, Massimo Nucci $^2$, Livio Finos $^3$, Massimiliano Pastore $^1$}

\maketitle

\begin{Schunk}
\begin{Sinput}
> # ++++++++++++++++++++++++++++++++++
> betapar <- function(mx,sx,n=NULL) {
+   vx <- sx^2
+   if (vx<(mx*(1-mx))) {
+     pezzo <- ((mx*(1-mx))/vx)-1
+     a <- mx*pezzo
+     b <- (1-mx)*pezzo
+   } else {
+     warning("adjusted formula by using n")
+     a <- mx*n
+     b <- (1-mx)*n
+   }
+   return(list(a=a,b=b))
+ }
> # +++++++++++++++++++++++++++
> snpar <- function(xi=0,omega=1,alpha=0) {
+   delta <- alpha/sqrt(1+alpha^2)
+   mu <- xi + omega * delta * sqrt( 2/pi )
+   sigma2 <- omega^2 * ( 1 - (2*delta^2)/pi )
+   return(list(mu = mu, sigma = sqrt(sigma2)))
+ }
> # +++++++++++++++++++++++++++
> sninvpar <- function( mu=0, sigma=1, xi=NULL, omega=NULL, alpha=0 ) {
+   
+   if (is.null(omega)) {
+     delta <- alpha/sqrt(1+alpha^2)
+     omega2 <- sigma^2 / ( 1 - (2*delta^2) / pi )
+     omega <- sqrt( omega2 )
+   }
+   
+   if (is.null(xi)) {
+     delta <- alpha/sqrt(1+alpha^2)
+     xi <- mu - omega * delta * sqrt( 2/pi )
+   }
+   
+   return( list( xi = xi, omega = omega, alpha = alpha ) )
+   
+ }
> # +++++++++ funzione colori default
> gg_color_hue <- function(n) {
+   hues = seq(15, 375, length = n + 1)
+   hcl(h = hues, l = 65, c = 100)[1:n]
+ }
> # +++++++++++++++++++++++++++++++
> #' @name min_normal_uniform
> #' @description Calcola il minimo tra la densità di una normale e di una uniforme
> #' @param x = x vector
> #' @param normPars = parametri della normale: media e dev. standard
> #' @param unifPars = parametri della uniforme: minimo e massimo
> #' #' @param return.all = logical, if \code{TRUE} restituisce il data set completo delle densità delle due distribuzioni
> min_normal_uniform <- function( x = NULL, normPars = c(0,1), unifPars = c(0,1), return.all = FALSE ) {
+   
+   if (is.null(x)) x <- seq(-5,5,by=.1)
+   
+   y1 <- dnorm(x, normPars[1], normPars[2])
+   y2 <- dunif(x, unifPars[1], unifPars[2])
+   dy <- ifelse(y1<y2, y1, y2)
+   
+   gData <- data.frame( x, y1, y2, dy )  
+   
+   if (return.all) {
+     return( list( gData = gData ) )
+   } else {
+     return( dy )  
+   }
+ 
+ }
> # +++++++++++++++++++++++++++++++++++
> #' @name min_dskew_normal
> #' @description Calcola il minimo tra due densità Skew-Normal
> #' @param x = x vector
> #' @param xi = vector of location parameters
> #' @param omega = vector of scale parameters
> #' @param alpha = vector of skewness parameters
> #' @param plot = logical, if \code{TRUE} produce la rappresentazione grafica delle densità 
> #' e dell'area di sovrapposizione
> #' @param return.all = logical, if \code{TRUE} restituisce il data set completo delle 
> #' densità delle due distribuzioni
> min_dskew_normal <- function( x = seq( -5, 5, by = .01 ), xi = c(0,0), omega = c(1,1), alpha = c(0,0), 
+                               return.all = FALSE ) {
+   
+   if (length(xi)==1) xi <- rep(xi,2)
+   if (length(omega)==1) omega <- rep(omega,2)
+   if (length(alpha)==1) alpha <- rep(alpha,2)
+   
+   require( sn )
+   y1 <- dsn( x, xi = xi[1], omega = omega[1], alpha = alpha[1] )
+   y2 <- dsn( x, alpha = alpha[2], xi = xi[2], omega = omega[2] )
+   dy <- ifelse( y1 < y2, y1, y2 )
+   gData <- data.frame( x, y1, y2, dy )  
+   
+   if (return.all) {
+     return( list( gData = gData ) )
+   } else {
+     return( dy )  
+   }
+ }
> # ++++++++++++++++++++++++++++
> #' @name permTest
> #' @description Esegue test di permutazione su overlapping, 
> #'differenza tra medie e rapporto tra varianze
> #' @param xList = lista di due elementi (\code{x1} e \code{x2} ) 
> #' @param B = numero di permutazioni da effettuare
> #' @param ov.type = character, type of index. If type = "2" returns the proportion of the overlapped area between two or more densities. 
> #' @note Il confronto tra le medie è ad una sola coda e 
> #'testa l'ipotesi che le medie siano uguali vs l'ipotesi
> #'che la seconda sia maggiore della prima (\code{mean(x2) > mean(x1)})
> #' @return Restituisce una lista con tre elementi:
> #' obs = vettore dei valori osservati di non-sovrapposizione 
> #'       \coed{1-eta}, differenza tra le medie (\code{mean(x2)-mean(x1)}), 
> #'       rapporto tra le varianze
> #' perm = matrice Bx3 con i valori delle stesse statistiche ottenute
> #'        via permutazione
> #' pval = vettore con i tre p-values   
> permTest <- function( xList, B = 1000, ov.type = c("1","2")) {
+   
+   require(overlapping)
+   ov.type <- match.arg(ov.type)
+   names(xList) <- c("x1","x2")
+   N <- unlist( lapply(xList,length) )
+   
+   # observed statistics
+   zobs <- 1-overlap( xList, type = ov.type )$OV
+   dobs <- diff( unlist( lapply(xList, mean) ) )
+   Fobs <-  with( xList, var.test(x1,x2)$statistic )
+   OBS <- data.frame(zobs,dobs,Fobs)
+   Mobs <- matrix( OBS, nrow=B, ncol=3, byrow = TRUE )
+   
+   Yperm <- t( sapply(1:B, function(b){
+     xperm <- sample( unlist( xList ) )
+     xListperm <- list( x1 = xperm[1:N[1]], x2 = xperm[(N[1]+1):(sum(N))] )
+     
+     zperm <- 1 - overlap( xListperm, type = ov.type )$OV
+     dperm <- diff( unlist( lapply(xListperm, mean) ) )
+     Fperm <-  with( xListperm, var.test(x1,x2)$statistic )
+     
+     out <- c(zperm,dperm,Fperm)
+     names(out) <- c("zperm","dperm","Fperm")
+     out
+   }) )
+   
+   PVAL <- apply( Yperm > Mobs, 2, mean )
+   L <- list(obs=OBS,perm=Yperm,pval=PVAL)
+   
+   return(L)
+ }
> 
> 
\end{Sinput}
\end{Schunk}

\begin{abstract}
The present contribution aims to compare both commonly and less commonly used statistical methods in psychological sciences to evaluate their utility in tailored cases. Specifically, the paper proposes applying the Permutation test alongside the Overlapping index to estimate effects of interest in psychological science. Starting from real and openly available data, we simulated different scenarios focusing on residual distribution characteristics.  The present contribution provides practical tools for considering, and deciding which statistical methods are useful and sufficient considering the features of data distribution. Subsequently, we present a Simulation study to illustrate the practical implications and reliability of each approach, particularly valuable in scenarios commonly encountered in quantitative psychology, where navigating data characteristics and adhering to or deviating from test assumptions is crucial. The findings underscore the necessity of choosing statistical methods that are resilient to the complexities inherent in psychological data, where assumption violations are often inevitable.
\end{abstract}


\section{Statistical testing choices in Psychology}

    Methodological choices in cognitive and behavioral sciences aim to combine data richness with data collection feasibility, and at the same time they aim to land on valid interpretation based on reliable and robust statistical methods. Classic examples, like reaction times, demonstrate how specific measures have achieved such an acceptable trade-off, and for example, this is true even by comparing the framework of in lab \textit{vs} online data collection \cite{semmelmann2017online}. Nevertheless, even in the fortunate case of reaction times which have widespread and solid epistemic rationale of use \cite{grosjean2001timing, proctor2018hick, silverman2010simple} significance testing often relies on the rigid application of a few statistical methods that have gained popularity among the scientific community and are perpetrated \textit{perinde ac cadaver} by formal guidelines \cite{cumming2012statistical}, even if their limits and risks have always been noted in the field of psychology and beyond \cite{boneau1960effects}. 
    
    In fact, there is a growing caution against blindly using statistical tools and analytical methods without a deep understanding of their assumptions and implications \cite{scheel2021hypothesis}. In other words, it is increasingly apparent that relying solely on significance testing as a trustworthy measure is improbable without considering the assumptions inherent to specific statistical methods, such as the t-test, across various scenarios in psychology. In fact, considering the particular circumstances of application has consistently been crucial advice when deciding on significance testing methods \cite{fisher1925theory}.
    
    \vspace{0.2cm}
    
    The present contribution aims to compare both commonly and less commonly used statistical methods in psychological sciences to evaluate their utility in specific and tailored cases. Through an illustrative example, we re-analyze reaction times coming from a real and available dataset of a reading task with high- and low-frequency words. Specifically, the present work proposes applying the Permutation test \cite{pesarin2010permutation} alongside the Overlapping index \cite{pastore2019measuring} to estimate effects of interest in psychological sciences. 
Of note, the proposed approach is practically declined by using a word reading study, however the very same logic can extend to other measures in psychology sciences. Importantly, by simulating different scenarios focusing on residual distribution characteristics, the paper provides practical tools for considering, and deciding which statistical methods are useful and sufficient considering the features of data distribution. Understanding and applying significance testing properly is crucial to deriving meaningful conclusions from psychological research. Accordingly, we offer practical and reproducible tools to manage the assumptions underlying these analytical approaches, and increase awareness in significance testing in psychology.

\vspace{0.2cm}
In particular, when the assumptions of linear regression, such as normality and homoscedasticity, are not met, alternative methods become optimal. The use of indices calculated on empirical distributions is particularly beneficial when these assumptions are violated \cite{pastore2015analisi}. Specifically, when using a t-test to compare two groups or two experimental conditions using a given variable, it functions as a straightforward version of linear regression. This statistical process necessitates assumptions about the residuals, such as their independence and normal distribution, to be met. In cases such as reaction times, these assumptions might be violated if they are not properly addressed. Sometimes, two populations might present the same mean for a given variable, yet their distributions largely differ in other parameters, leading to genuinely distinct groups (see figure \ref{fig:equalmeans}).

\vspace{0.2cm}
The remainder of this article is structured as follows. First, we introduce the concept of the Overlapping Index, providing foundational definitions and highlighting its importance. Next, we define the Permutation approach and explore its application to the Overlapping Index, showcasing its relevance in statistical analysis. Subsequently, we present a Simulation study to illustrate the practical implications and reliability of the overlapping index utilizing permutations.

In the following section, we compare several statistical tests: the t-test for independent samples assuming equal variance, the Welch test for independent samples, the Wilcoxon test for independent samples, the Permutation test on the complement of the Overlapping index ($\zeta$ = 1 − $\eta$), which serves as a measure of intergroup differences, the F test for homogeneity of variances, and the Kolmogorov-Smirnov test for comparing two distributions.

The rationale behind these steps involves first introducing the concept of the Overlapping Index ($\eta$), which is crucial because it provides an intuitive measure of similarity between distributions by quantifying the overlapping area of their probability density functions, a common question in quantitative psychology. The Permutation approach is then defined and applied to the Overlapping Index, demonstrating how non-parametric methods can offer insights without relying on typical parametric assumptions. Specifically, the Permutation test involves shuffling data points to generate a sampling distribution, allowing the calculation of a p-value and highlighting its utility in assessing the statistical significance of the Overlapping Index. Next, a Simulation study uses a real dataset to simulate various scenarios that might meet or violate the assumptions of different statistical tests, modeling a range of conditions reflective of real-world complexities in psychological research. This simulation facilitates the evaluation of the statistical power (probability of correctly rejecting a false null hypothesis) and the type I error rate (likelihood of incorrectly rejecting a true null hypothesis) of each approach. To this end, several statistical tests are compared: the t-test for independent samples, assuming equal variances; the Welch test, which does not assume equal variances; the Wilcoxon test, suitable for ordinal data or when normality is not assumed; the Permutation Test on the Overlapping Index Complement ($\zeta$ = 1 − $\eta$), providing a non-parametric approach to evaluate intergroup differences; the F test for examining the homogeneity of variances; and the Kolmogorov-Smirnov test for comparing two distributions regardless of their underlying forms. These results enable researchers to visualize and comprehend the reliability and utility of each approach, particularly valuable in scenarios commonly encountered in quantitative psychology, where navigating data characteristics and adhering to or deviating from test assumptions is crucial.

Finally, we discuss the results, offering insights into the strengths and limitations of the Permutation-based Overlapping index and its potential applications in psychological sciences.

\section{Overlapping Index}

Cognitive and experimental researchers regularly strive to uncover evidence that supports their hypotheses by examining statistical differences or similarities among groups or conditions. Frequently, this involves measuring the difference between two distribution within the same dependent variable, basically relying on their mean values using metrics like the t statistic, Cohen's \textit{d}, or \textit{U} statistics. The goal in each scenario is to estimate the magnitude of these differences to identify them as significant effects. However, a complementary perspective can be gained through the overlapping index ($\eta$), which intuitively quantifies the common area between two or more probability density functions. This measure serves as an additional tool for comparing distributions, where greater overlap indicates similarity, and a decrease in $\eta$ signals divergence \cite{pastore2019measuring}.

\vspace{0.2cm}

The index $\eta$ of two empirical distributions varies from zero -- when the distributions are completely disjoint -- and one -- when they are completely overlapped \cite{pastore2018overlapping}. The simple interpretation of the overlapping index ($\eta$) makes its use particularly suitable for many applications \cite{moravec1988sensor, viola1997alignment, inman1989overlapping, milanovic2002decomposing}.

Assuming two probability density functions $f_A (x)$ and $f_B (x)$, the overlapping index $\eta: \mathbb{R}^n \times \mathbb{R}^n \to [0,1] $ is formally defined in the following way:


\begin{eqnarray}
\eta (A,B) = \int_{\mathbb{R}^n} min [f_A (x),f_B (x)] dx
\end{eqnarray} 

where, in the discrete case, the integer can be replaced by summation. As previously mentioned, $\eta (A,B)$ is normalized to one and when the distributions of A and B do not have points in common, meaning that $f_A (x)$ and $f_B (x)$ are disjoint, $\eta (A,B) = 0$. This index provides an intuitive way to quantify the agreement between $A$ and $B$ based on their density functions \cite{inman1989overlapping}. 

\begin{Schunk}
\begin{Sinput}
> normPars <- c(10,2)
> unifPars <- c(0,20)
> n <- 30 
\end{Sinput}
\end{Schunk}




\vspace{.3cm}

In theory the two distributions are defined in the following way: 
$y_1 \sim \text{Normal}(10)$ 
$y_2 \sim \text{Unif}(0)$  

The true $\eta = 0.43$.


\vspace{.3cm}
To quickly illustrate a visual representation of the overlapping area in two given distributions we present the following example: a sample of 30 observations generated from a normal distribution with mean of 10 and standard deviation on 2 and a sample of 30 generated from a random uniform with the minimum value of 0 and the maximum of 20.



\begin{Schunk}
\begin{Sinput}
> library(overlapping)
> set.seed(36)
> x <- rnorm(n, normPars[1], normPars[2])
> y <- runif(n, unifPars[1], unifPars[2])
> LIST<-list(x,y)
> OV <- overlap(LIST)
> TTEST <- t.test(x,y, var.equal = TRUE)
> TTESTUNEQUAL <- t.test(x,y, var.equal = FALSE)
> Y <- stack( data.frame(y1=x,y2=y) )
> 
\end{Sinput}
\end{Schunk}

The figure \ref{fig:equalmeans} shows how two distributions with almost same mean could still be very different from each other with the overlapping area being $\hat{\eta} = 0.46$. 


\begin{Schunk}
\begin{Sinput}
> myData <- data.frame( x = seq(0,20,by=.1) )
> myData$y1 <- dnorm(myData$x, normPars[1], normPars[2] )
> myData$y2 <- dunif(myData$x, unifPars[1], unifPars[2])
> myData$h <- with(myData, ifelse( y1 < y2, y1, y2 ))
> AREA <- integrate( min_normal_uniform, -Inf, Inf, normPars = normPars, unifPars = unifPars )
> 
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
> library(cowplot)
> plot_grid(
+   ggplot(myData,aes(x,y1)) + geom_line() + geom_line(aes(x,y2)) + 
+     geom_ribbon(aes(ymin=0,ymax=h), alpha = .5) + xlab("") + ylab("") + 
+     scale_y_continuous( breaks = NULL ) + ggtitle("[A]"), 
+   
+   ggplot(Y, aes(values,fill=ind,color=ind)) + geom_density(alpha = .5) + xlab("") + theme(legend.title = element_blank()) + ylab("") + 
+     scale_y_continuous( breaks = NULL ) + guides(fill="none",color="none")+ ggtitle("[B]")
+ )
> 
> 
\end{Sinput}
\end{Schunk}


In this case, a t-test would not be able to detect such difference, as it does not take into account the different variance in the two groups. Even when using a Welch test, which does not assume equal variance, the test does is less informative ($t = 0.880631781019184$, $p = 0.384478167321231$) compared to the overlapping index.

\subsection{Permutation approach}

 Now we will introduce another approach which does not rely on the assumptions of linear models: the permutation approach. This is a non-parametric statistical method that can be used to determine statistical significance and it is most useful when the assumptions of parametric tests are not met \cite{pesarin2010permutation}. What the test does is to rearrange the data in many different ways and recalculates the test statistic each time. If we are thinking about a simple mean comparison (a t-test), the data in the two groups are mixed over and over and the t-value is calculated each time. If the two groups come from the same population, mixing the labels should give similar results to the ones observed. Else, if the two groups come from different populations, mixing tags should lead to very different results. From the empirical density of the permuted values it is possible to calculate the p-value as the probability to obtain an equal or more extreme value compared to the observed one. 

\subsection{Application of permutation test to the overlapping index}

If we are reasoning from the perspective of Null Hypothesis Significance Testing (NHST), we should define the null hypothesis as follows: $H_0: \eta = 1$,  meaning there is no difference between the distributions of data in the population. For this reason, it is more intuitive to work with the complement of $\eta$, which is  $1-\eta = \zeta$ which is the area of non-overlap, therefore, defining the null hypothesis as  $H_0:\zeta = 0$. When testing the difference between the two distributions, we will no longer be working with $\eta$, but with the complement $\zeta$. 

Even though the overlapping index has a simple interpretation, one could argue that it does not provide information on the significance of the parameter $\eta$, therefore, we decided to implement permutation testing to offer to the ones interested a value of significance. In particular, we implemented permutations test, to give a tool that tests differences in distributions in cases where other tests' assumptions would be violated.

The algorithm estimates the value of $\zeta$ on the observed data ($\hat{\zeta}$). Then, through permutation, the values of the two groups are randomly re-assigned to the groups for B times, estimating again the new value of  $\hat{\zeta}_b$. The times in which the estimate of $\hat{\zeta}_b$ on permuted data is higher than the one observed on real data is estimated ($\hat{\zeta}_b > \hat{\zeta}$) and then the found value is divided by B, returning the $p$-value. This approach is equivalent to the traditional parametric tests.

A typical example of data not respecting previously said assumptions is reaction times and for this purpose we present a real case of a dataset available online (citation of the OSF repository) on reaction times of word reading of high and low frequency words in English and we implement on the overlapping function the permutation test. 

