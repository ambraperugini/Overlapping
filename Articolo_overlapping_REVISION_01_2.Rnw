% \documentclass[twocolumn]{article}
\documentclass[10pt]{article}
\pagestyle{myheadings}
\usepackage{color}
\usepackage[italian,english]{babel}
\usepackage{hyperref}
\usepackage[margin=3cm]{geometry}
\usepackage{bm}
\usepackage{tikz}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{caption}
\captionsetup{font=footnotesize}
\usepackage{apacite}
\usepackage{booktabs}

% \usepackage[bottom]{footmisc} 

%\newcommand\BibTeX{{\rmfamily B\kern-.05em \textsc{i\kern-.025em b}\kern-.08em
%T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
<<include=FALSE>>=
library(knitr)
options(digits=3)
opts_chunk$set(fig.width=3, fig.height=3, dev="pdf",fig.align='center',echo=FALSE,results="hide",comment=NA,prompt=FALSE,warning=FALSE, cache = TRUE)
@
\usepackage{float}
\floatstyle{boxed}
\newfloat{program}{btp}{lop}
\floatname{program}{Box}
%\usepackage{mdframed}
%\definecolor{boxcol}{RGB}{213,226,238}
%\newmdenv[linecolor=boxcol,backgroundcolor=boxcol]{comments}


<<>>=
knitr::clean_cache()
rm(list=ls())
main <- getwd()

datadir <- paste0(main,"data/")

@


\begin{document}

\title{\textbf{\textit{How do my distributions differ?} \\ Significance testing for the Overlapping Index \\ using Permutation Test}} 
\author{ Giulia Calignano $^1$, Ambra Perugini $^1$, Massimo Nucci $^2$, Livio Finos $^3$, Massimiliano Pastore $^1$}

\date{}

\maketitle



<<>>=
# ++++++++++++++++++++++++++++++++++
betapar <- function(mx,sx,n=NULL) {
  vx <- sx^2
  if (vx<(mx*(1-mx))) {
    pezzo <- ((mx*(1-mx))/vx)-1
    a <- mx*pezzo
    b <- (1-mx)*pezzo
  } else {
    warning("adjusted formula by using n")
    a <- mx*n
    b <- (1-mx)*n
  }
  return(list(a=a,b=b))
}

# +++++++++++++++++++++++++++
snpar <- function(xi=0,omega=1,alpha=0) {
  delta <- alpha/sqrt(1+alpha^2)
  mu <- xi + omega * delta * sqrt( 2/pi )
  sigma2 <- omega^2 * ( 1 - (2*delta^2)/pi )
  return(list(mu = mu, sigma = sqrt(sigma2)))
}

# +++++++++++++++++++++++++++
sninvpar <- function( mu=0, sigma=1, xi=NULL, omega=NULL, alpha=0 ) {
  
  if (is.null(omega)) {
    delta <- alpha/sqrt(1+alpha^2)
    omega2 <- sigma^2 / ( 1 - (2*delta^2) / pi )
    omega <- sqrt( omega2 )
  }
  
  if (is.null(xi)) {
    delta <- alpha/sqrt(1+alpha^2)
    xi <- mu - omega * delta * sqrt( 2/pi )
  }
  
  return( list( xi = xi, omega = omega, alpha = alpha ) )
  
}

# +++++++++ default colour function
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

# +++++++++++++++++++++++++++++++
#' @#' @name min_normal_uniform
#' @description Computes the minimum between the density of a normal distribution and a uniform distribution.
#' @param x Numeric vector of x values.
#' @param normPars Parameters of the normal distribution: mean and standard deviation.
#' @param unifPars Parameters of the uniform distribution: minimum and maximum.
#' @param return.all Logical. If \code{TRUE}, returns the full dataset containing the densities of both distributions.
min_normal_uniform <- function( x = NULL, normPars = c(0,1), unifPars = c(0,1), return.all = FALSE ) {
  
  if (is.null(x)) x <- seq(-5,5,by=.1)
  
  y1 <- dnorm(x, normPars[1], normPars[2])
  y2 <- dunif(x, unifPars[1], unifPars[2])
  dy <- ifelse(y1<y2, y1, y2)
  
  gData <- data.frame( x, y1, y2, dy )  
  
  if (return.all) {
    return( list( gData = gData ) )
  } else {
    return( dy )  
  }

}



# +++++++++++++++++++++++++++++++++++
#' @name min_dskew_normal
#' @description #' @description Computes the minimum between two Skew-Normal density functions.
#' @param x Numeric vector of x values.
#' @param xi Vector of location parameters.
#' @param omega Vector of scale parameters.
#' @param alpha Vector of skewness parameters.
#' @param plot Logical. If \code{TRUE}, produces a graphical representation of the densities
#' and their overlapping area.
#' @param return.all Logical. If \code{TRUE}, returns the full dataset containing the
#' densities of the two distributions.
min_dskew_normal <- function( x = seq( -5, 5, by = .01 ), xi = c(0,0), omega = c(1,1), alpha = c(0,0), 
                              return.all = FALSE ) {
  
  if (length(xi)==1) xi <- rep(xi,2)
  if (length(omega)==1) omega <- rep(omega,2)
  if (length(alpha)==1) alpha <- rep(alpha,2)
  
  require( sn )
  y1 <- dsn( x, xi = xi[1], omega = omega[1], alpha = alpha[1] )
  y2 <- dsn( x, alpha = alpha[2], xi = xi[2], omega = omega[2] )
  dy <- ifelse( y1 < y2, y1, y2 )
  gData <- data.frame( x, y1, y2, dy )  
  
  if (return.all) {
    return( list( gData = gData ) )
  } else {
    return( dy )  
  }
}

# ++++++++++++++++++++++++++++
#' @name permTest
#'#' @description Performs permutation tests on the overlapping index,
#' mean difference, and variance ratio.
#' @param xList A list with two elements (\code{x1} and \code{x2}).
#' @param B Number of permutations to perform.
#' @param ov.type Character, type of index. If \code{type = "2"}, returns the proportion
#' of overlapped area between two or more densities.
#' @note The comparison between means is one-tailed and tests the hypothesis
#' of equal means against the alternative that the second mean is greater
#' than the first (\code{mean(x2) > mean(x1)}).
#' @return A list with three elements:
#' \item{obs}{Vector of observed statistics: non-overlap value
#' (\code{1 - eta}), mean difference (\code{mean(x2) - mean(x1)}),
#' and variance ratio.}
#' \item{perm}{A B x 3 matrix containing the same statistics obtained
#' through permutation.}
#' \item{pval}{Vector containing the three corresponding p-values.   
permTest <- function( xList, B = 1000, ov.type = c("1","2")) {
  
  require(overlapping)
  ov.type <- match.arg(ov.type)
  names(xList) <- c("x1","x2")
  N <- unlist( lapply(xList,length) )
  
  # observed statistics
  zobs <- 1-overlap( xList, type = ov.type )$OV
  dobs <- diff( unlist( lapply(xList, mean) ) )
  Fobs <-  with( xList, var.test(x1,x2)$statistic )
  OBS <- data.frame(zobs,dobs,Fobs)
  Mobs <- matrix( OBS, nrow=B, ncol=3, byrow = TRUE )
  
  Yperm <- t( sapply(1:B, function(b){
    xperm <- sample( unlist( xList ) )
    xListperm <- list( x1 = xperm[1:N[1]], x2 = xperm[(N[1]+1):(sum(N))] )
    
    zperm <- 1 - overlap( xListperm, type = ov.type )$OV
    dperm <- diff( unlist( lapply(xListperm, mean) ) )
    Fperm <-  with( xListperm, var.test(x1,x2)$statistic )
    
    out <- c(zperm,dperm,Fperm)
    names(out) <- c("zperm","dperm","Fperm")
    out
  }) )
  
  PVAL <- (apply( Yperm >= Mobs, 2, sum )+1)/(nrow(Yperm)+1)
  L <- list(obs=OBS,perm=Yperm,pval=PVAL)
  
  return(L)
}

# ++++++++++++++++++++++++++
#' @name numeriAPA
#' #' @description Removes the leading zero from values in the interval [0, 1],
#' according to APA reporting guidelines.
numeriAPA <- function(x) {
  gsub("0\\.","\\.",as.character(x))
}

## +++++++++++++++++++++++++++++++++++++++++++
#' #' @title Correlation plot
#' @param RR Correlation matrix.
#' @param U Vector specifying the plot margins.
plot_correlation <- function(RR,values=FALSE,textsize=12,legendsize=10,angle=0, corrsize=4, U=c(0,0,0,0), short.names = FALSE) {
  require(ggplot2)
  require(reshape2)
  RR <- melt(RR)
  NAME <- "Correlation"
  
  if (short.names) {
    levels(RR$Var2) <- paste0("(",1:length(levels(RR$Var2)),")")
  }
  
  GGcor <- ggplot(RR,aes(Var2,Var1,fill=value))+geom_tile()+
    scale_fill_gradient2(low = "blue", high = "red", mid = "white",midpoint =0, space = "Lab",name=NAME)+
    xlab("")+ylab("")+coord_fixed()+
    theme(plot.margin = unit(U, "cm"),
          text=element_text(size=textsize),
          axis.text.x=element_text(angle=angle),
          legend.text = element_text(size = legendsize),legend.title = element_text(size = legendsize)) 
  
  if (values) {
    GGcor <- GGcor + geom_text(aes(Var2, Var1, label = round(value,2)), color = "black", size = corrsize )
  }
  print(GGcor)
}

# ++++++++++++++++++++++++++++
#' @name perm.test
#' #' @description Performs a permutation test on the overlapping index.
#' @param x A list with two elements (\code{x1} and \code{x2}).
#' @param B Number of permutations to perform.
#' @return A list with three elements:
#' \item{obs}{Observed value of non-overlap (\code{1 - eta}).}
#' \item{perm}{Values of the same statistic obtained via permutation.}
#' \item{pval}Permutation-based p-value.
#' 
perm.test <- function (x, B = 1000, 
               return.distribution = FALSE, ...)
{
  
  # control 
  args <- c(as.list(environment()), list(...))
  pairsOverlap <- ifelse(length(x)==2, FALSE, TRUE)
  
  N <- unlist( lapply(x,length) )
  out <- overlap(x, ...)
  
  if (pairsOverlap) {
    zobs <- 1-out$OVPairs
    Zperm <- t(sapply(1:B, function(b) {
      xListperm <- perm.pairs( x )
      ovperm <- unlist( lapply(xListperm, overlap, ...) )
      zperm <- 1 - ovperm
    }))
  } else {
    zobs <- 1-out$OV
    Zperm <- t(sapply(1:B, function(b) {
      xperm <- sample( unlist( x ) )
      xListperm <- list( x1 = xperm[1:N[1]], x2 = xperm[(N[1]+1):(sum(N))] )      
      zperm <- 1 - overlap( xListperm, ... )$OV
    }))
  }
  
  
  ## (sum( zperm >= obsz ) +1) / (length( zperm )+1) LIVIO
  
  colnames(Zperm) <- gsub("\\.OV","",colnames(Zperm))
  if (nrow(Zperm) > 1) {
    
    ZOBS <- matrix( zobs, nrow(Zperm), ncol(Zperm), byrow = TRUE )
    pval <- (apply( Zperm > ZOBS, 2, sum ) + 1)/ (nrow(Zperm)+1)
    
  } else {
    pval <- (sum(Zperm > zobs)+1) / (length(Zperm)+1)
  }
  
  if (return.distribution) {
    return(list(Zobs = zobs, pval = pval, Zperm = Zperm))
  } else {
    return(list(Zobs = zobs, pval = pval))  
  }
  
  
}

@

\begin{abstract}
\textcolor{red}{Psychological research frequently relies on statistical tests targeting single distributional parameters, typically means, despite empirical data often differing in variance, skewness, or overall shape. We introduce the $\zeta$-Overlapping test, a permutation-based inferential procedure built on the Overlapping Index, an effect size quantifying similarity between empirical distributions. The proposed approach evaluates global distributional differences without relying on parametric assumptions. Through simulations manipulating mean, variance, skewness, and sample size, we compare the $\zeta$-Overlapping test with commonly used procedures (t, Welch, Wilcoxon–Mann–Whitney, Kolmogorov–Smirnov, and variance tests). Results show accurate Type I error control and substantially higher power than parameter-specific tests across a wide range of non-normal scenarios, with strong performance even at small sample sizes. An applied example using reaction-time data demonstrates how distributional overlap detects differences missed by mean-based analyses. Rather than replacing traditional tests, the method provides a theoretically aligned global assessment that encourages distribution-aware inference and integration of visualization and descriptive analysis into statistical workflows. The $\zeta$-Overlapping framework supports ongoing methodological shifts in psychological science toward robust, assumption-light, and interpretable statistical reasoning.}

\end{abstract}

Keywords: \textcolor{red}{simulation, type I error, data visualization, reaction time, Nonparametric inference}

\section{Statistical testing choices in Psychology}

\textcolor{red}{Cognitive psychology frequently relies on comparisons between experimental conditions to infer psychological effects. Standard analyses typically focus on single summary statistics, such as mean differences, and depend on assumptions that are rarely satisfied by behavioral data. Yet cognitive measures often differ in dispersion, skewness, or tail behavior rather than central tendency alone. Researchers also often need to demonstrate that groups are comparable before interpreting experimental effects, for instance, to argue that observed differences are attributable to a manipulation rather than pre-existing sample characteristics. In practice, this comparability is usually inferred from non-significant differences in group means, sometimes accompanied by separate tests of variance, implicitly treating equality of means as evidence of overall similarity. However, groups with similar averages may still differ substantially in distributional structure, leading researchers to rely on multiple parameter-specific tests that provide only a partial assessment of similarity. In this work, we propose a distribution-based statistical test that evaluates both similarity and difference by measuring the overlap between empirical distributions. The test derives form the Overlapping Index \cite{gini1943nuovi, overlapping:package}, which is the area intersected by two or more probability density functions, allowing to easily quantify the similarity or difference among samples \cite{inman1989overlapping}. The implementation of the test through permutations permits to test global differences without relying on rigid assumptions.}

    \vspace{0.2cm}

\textcolor{red}{The need for a distribution-level approach is especially clear in research areas where psychological data naturally depart from symmetry and homogeneity assumptions. Reaction time paradigms- such as attentional cueing e.g., Posner cueing task; \cite{calignano2024words,posner1980orienting}, lexical decision tasks \cite{gastaldon2025linguistic,balota2011moving}, social cueing tasks \cite{lorenzoni2023linguistic,geiger2018social}, and eye-tracking or pupillometric studies \cite{calignano2021unique,cavanagh2014eye}, typically yield right-skewed distributions containing outliers \cite{ratcliff1993methods,heathcote2002quantile}. In these contexts, mean-based tests may indicate no difference even when the distributions differ substantially in spread or shape, and even significant mean effects fail to capture the full structure of the data \cite{matzke2009psychological,rieger2020model,pastore2019measuring}.}

\vspace{0.2cm}

\textcolor{red}{
Comparable patterns emerge in other areas of psychological science. Developmental studies often reveal changes in variability and behavioral strategies rather than average performance \cite{manybabies2020quantifying,byersheinlein2021multilab,rouder2019psychometrics}. Similarly, in clinical contexts, comparisons of anxiety scores between clinical and control groups, or between patients and caregivers \cite{spaggiari2024examining}, may involve similar mean scores alongside pronounced differences in extreme responses \cite{knowles2021anxiety}. Across these domains, the inferential question shifts from whether averages differ to whether distributions themselves differ, motivating methods that directly quantify distributional similarity e.g., overlapping indices;\cite{pastore2019measuring,inman1989overlapping}.}

\vspace{0.2cm}
\textcolor{red}{To date, awareness on the importance of the generative process of the data is rising and there is a growing attention against blindly using statistical tools and analytical methods without a deep understanding of their assumptions and implications. \citeA{scheel2021hypothesis} caution against the routine and uncritical application of hypothesis tests detached from theoretical grounding advocating for theory-aligned analysis. In this spirit, the present proposal not only aims to guide the researcher in an aware and thoughtful choice of statistical tests, but also advocates for the implementation of descriptive statistics and data visualization in the routine workflow of data analysis, encouraging a more explicit focus on the structure of empirical distributions. As originally noted by \citeA{fisher1925theory}, the choice of a statistical test should always be guided by the context and purpose of its application.}

    \vspace{0.2cm}

\textcolor{red}{   This contribution introduces a novel approach to statistical testing, particularly for comparing two groups/conditions. Specifically, the paper proposes a new test, called the $\zeta$-Overlapping test, which applies the Permutation Test \cite{pesarin2001} alongside the Overlapping Index \cite<$\eta$,>{pastore2019measuring} to compare empirical distributions. The Overlapping index, and its proposed test, aims to promote reflection on the structure and shape of the data instead of a blind use of a new inferential tool. The application of the test should not be used as mere alternative test with fewer assumptions but as a thoughtful choice in tailored cases (i.e. preliminary checks between groups/conditions, cases of violation of assumptions).}
   
       \vspace{0.2cm}

\textcolor{red}{The $\zeta$-Overlapping test has four main advantages. First, the core strength of the $\zeta$-Overlapping test is that it derives from an effect size and as such is highly intuitive. By quantifying the degree of overlap two density distributions, it allows for an easy comprehension of the test. The focus of the test on the entire distribution of the data, combined with the solicitation to implement in workflow descriptive statistics and data visualization contributes to increasing awareness on the generative process of the data, as already mentioned, essential for drawing meaningful conclusions in psychological research.}

    \vspace{0.2cm}

\textcolor{red}{The second advantage is its ability to simultaneously account for and compare the mean, variance, and shape with a single test. The $\zeta$-Overlapping test is a global distributional test, as such one can lower the inflation of false positive rates that can arise when multiple parameter-specific tests are applied sequentially, a scenario commonly encountered in preliminary or baseline checks. This particular use of the test aligns with \citeA{scheel2021hypothesis} recommendations by avoiding fishing expeditions for significant effects.}

\vspace{0.2cm}

\textcolor{red}{The third advantage relies in the fact that the proposed test can also be naturally extended to paired samples, making it suitable for repeated-measures designs commonly adopted in experimental psychology. In these settings, differences between conditions are evaluated within the same individuals, allowing individual variability to be explicitly preserved. The permutation procedure is implemented by shuffling condition labels within participants rather than across groups, thus maintaining the dependency structure of the data. This approach incorporates individual differences directly into the inferential process while providing a distribution-level comparison between conditions. An example based on real data illustrating this application is presented in the article, and all code required to reproduce the analyses is openly available.}

    \vspace{0.2cm}

\textcolor{red}{Lastly, the $\zeta$-Overlapping test offers an alternative tool to address the assumptions issue. Given that parametric tests commonly used for statistical inference rely on strong assumptions, such as normality and homoscedasticity, assumptions that are unlikely to be met in many areas of psychological research (i.e. reaction times, accuracy, proportions), alternative methods like this one become optimal. In cases of small sample sizes, when tests are more sensitive to assumptions violations, an alternative choice that is more adherent to the empirical distribution of the data is preferable.}

\vspace{0.2cm}

The remainder of this article is structured as follows. First, we introduce the concept of the Overlapping Index, providing foundational definitions and highlighting its importance. Next, we define the Permutation approach and explore its application to the Overlapping Index. With a practical application on a real case of RTs, evidence is provided for its relevance in statistical analysis. Subsequently, we present a Simulation study to illustrate the practical implications and the performance of the Overlapping index utilizing permutations. By simulating different scenarios, we compare statistical tests used in the psychological sciences with this novel approach, evaluating their control of Type I error and power. Finally, we discuss the results and provide the readers with an easy to implement workflow using the $\zeta$-Overlapping test, offering insight into the strengths and limitations of the Permutation-based Overlapping Index and its potential applications in psychological sciences.

    \vspace{0.2cm}

\section{Methods}

    \vspace{0.2cm}

\subsection{Overlapping Index}

\vspace{0.2cm}
The Overlapping Index ($\eta$) is an intuitive way to define the area intesected by two or more empirical density functions \cite{pastore2019measuring}. In a simple way, two distributions are similar when their distribution functions overlap, and as $\eta$ diminishes, the two distributions differ.
The $\eta$ index varies from zero -- when the distributions are completely disjoint -- and one -- when they are completely overlapped \cite{pastore2018overlapping}. The simple interpretation of the overlapping index ($\eta$) makes its use particularly suitable for many applications \cite<e.g.>{jensen+sanner:2021,garofalo+al:2022,schuetze+yan:2023,karrobi+al:2023,sirbiladze+al:2024,habibi+al:2024,ricote+al:2024,rossi+al:2024,einbeck+al:2024,wachendorfer+oeberst:2024,rohrbach:2024,hawkins+al:2024,upadhayay+al:2024,conversano+al:2024,pietrabissa+al:2024,nougaret+al:2024,greene+al:2024}.

    \vspace{0.2cm}

More formally, assuming two probability density functions $f_A (x)$ and $f_B (x)$, the Overlapping Index $\eta: \mathbb{R}^n \times \mathbb{R}^n \to [0,1] $ is defined in the following way:


\begin{eqnarray}
\eta (A,B) = \int_{\mathbb{R}^n} min [f_A (x),f_B (x)] dx
\end{eqnarray} 

where, in the discrete case, the integer can be replaced by summation. As previously mentioned, $\eta (A,B)$ is normalized to one and when the distributions of A and B do not have points in common, meaning that $f_A (x)$ and $f_B (x)$ are disjoint, $\eta (A,B) = 0$. This index provides an intuitive way to quantify the agreement between $A$ and $B$ based on their density functions \cite{inman1989overlapping}. 

<<warning=FALSE,message=FALSE>>=

library(overlapping)

normPars <- c(10,2)
unifPars <- c(0,20)
n <- 30 


set.seed(36)

x <- rnorm(n, normPars[1], normPars[2])
y <- runif(n, unifPars[1], unifPars[2])

LIST<-list(x,y)
OV <- overlap(LIST)
TTEST <- t.test(x,y, var.equal = TRUE)
TTESTUNEQUAL <- t.test(x,y, var.equal = FALSE)

Y <- stack( data.frame(y1=x,y2=y) )

@


\vspace{.3cm}

To quickly illustrate an example of the overlapping area, in figure \ref{fig:equalmeans} are represented two different empirical densities. In panel [A], are depicted two density distributions, a Normal(\Sexpr{normPars[1]},\Sexpr{normPars[2]}) and a Uniform(\Sexpr{unifPars[1]},\Sexpr{unifPars[2]}); note that the two distributions have the same mean (\Sexpr{normPars[1]}), but different variance, \Sexpr{normPars[2]^2} and \Sexpr{round((unifPars[2]-unifPars[1])^2*1/12, 1)} respectively. % mettiamo anche il vero valore di overlapping?
In the panel [B] are represented the empirical densities of two random samples of \Sexpr{n} observations drawn from the two populations specified as in panel [A]; the estimated overlapping area being $\eta = \Sexpr{round(OV$OV,2)}$.

\vspace{.3cm}

The figure \ref{fig:equalmeans} shows how two distributions with almost same mean could still be very different from each other with the overlapping area being $\hat{\eta} = \Sexpr{round(OV$OV,2)}$. In this case, the $t$-test focuses on mean differences, therefore correctly does not rejects the null hypothesis, even though the degree of similarity of the two densities is only \Sexpr{round(OV$OV*100)}\%, in other words, the difference is about \Sexpr{round((1-OV$OV)*100)}\%. Moreover, we remind that the $t$-test in this case is far from ideal as the two distributions have different variances.

    \vspace{0.2cm}

<<>>=
myData <- data.frame( x = seq(0,20,by=.1) )
myData$y1 <- dnorm(myData$x, normPars[1], normPars[2] )
myData$y2 <- dunif(myData$x, unifPars[1], unifPars[2])
myData$h <- with(myData, ifelse( y1 < y2, y1, y2 ))


AREA <- integrate( min_normal_uniform, -Inf, Inf, normPars = normPars, unifPars = unifPars )

@

<<equalmeans,fig.cap=paste0("Comparison of a normal distribution and a uniform distribution with same mean, ",normPars[1],", and different variances, ",normPars[2]^2," and ",round((unifPars[2]-unifPars[1])^2*1/12, 1),", respectively."), fig.width=6>>=
library(cowplot)

theme_set(theme_bw())
plot_grid(
  ggplot(myData,aes(x,y1)) + geom_line() + geom_line(aes(x,y2)) + 
    geom_ribbon(aes(ymin=0,ymax=h), alpha = .5) + xlab("") + ylab("") + 
    scale_y_continuous( breaks = NULL ) + ggtitle("[A]"), 
  
  ggplot(Y, aes(values,fill=ind,color=ind)) + geom_density(alpha = .5) + xlab("") + theme(legend.title = element_blank()) + ylab("") + 
    scale_y_continuous( breaks = NULL ) + guides(fill="none",color="none")+ ggtitle("[B]"),
  
  ncol = 2
)


@

\textcolor{red}{Of note, although the $\zeta$-Overlapping test is nonparametric in that it does not assume any specific parametric form for the underlying distributions and relies on permutation for inference, it does require estimating empirical density functions using kernel density estimation (KDE). Like all nonparametric estimators, KDE introduces smoothing parameters (e.g., bandwidth) that can affect the precision of the overlap estimate. While standard bandwidth rules (e.g., Silverman’s rule) work well in many scenarios, special care is required in cases of bounded data, where standard kernels may yield biased estimates near the boundaries. In such cases, boundary-corrected KDE methods or data transformations (e.g., logit for proportion data) can be used to improve accuracy. We note that KDE is widely accepted in psychological research (e.g., for modeling reaction time distributions). Nonetheless, researchers should be mindful of KDE characteristics when applying the method in bounded or sparse data contexts.}

\subsection{Permutation approach}

Permutation tests, also known as randomization tests, are a class of nonparametric statistical significance tests. The concept dates back to the work of R.A. Fisher in the 1930s, in particular his book \textit{The Design of Experiments} \cite{fisher:1935}. The theoretical foundations were further developed by E.J.G. Pitman in his seminal papers of 1937 \cite{pitman1937significance} and 1938 \cite{pitman1938significance}. The basic principle of permutation testing is based on the idea of rearranging observed data to generate a null distribution. This approach assumes that if the null hypothesis is true, then all possible arrangements of the data are equally likely, i.e., each permuted sample has the same probability as the observed one. By resampling the data, we can obtain the distribution of the test statistic under the null hypothesis without making any assumptions about the underlying data generating process. This is particularly valuable when dealing with small sample sizes or when the assumptions of parametric tests are not met. The observed test statistic is then compared to this empirically derived null distribution to determine the probability of obtaining such a result by chance alone \cite{pesarin2001}.

    \vspace{0.2cm}
    
\textcolor{red}{The permutation approach allows the adoption of any test statistic chosen by the user, including statistics designed for paired samples. In the case of paired data, observations are not exchanged between groups; instead, condition labels are permuted within each participant. This means that the relationship between paired observations is preserved while testing whether the observed difference between conditions could arise by chance. As a result, the procedure naturally accounts for individual differences while maintaining the logic of permutation-based inference. For example, if we are thinking about comparing the means of the two manipulation checks within a sample, we could choose a $t$-test statistic for repeated measures; the data in the two conditions are permuted and the $t$ value is calculated each time. If the two conditions} come from the same population, the $t$-statistic computed on the observed data should be close to 0; the $t$-statistic computed on randomly permuted data will also give values close to zero. Therefore, the randomly generated test statistic and the observed one have the same -- nonparametric -- distribution.  Otherwise, if the two groups come from populations with different means, the $t$-statistic computed on the observed data will be far from zero, while the $t$-statistic computed on the permuted data will be around zero.

    \vspace{0.2cm}

The $p$-value is the probability of obtaining an equal or more extreme $t$-statistic compared to the observed one:

\begin{eqnarray}
p=\frac{(\#_{b=1}^B |t_b|\geq |t|)+1}{B+1}
\end{eqnarray}

where $B$ is the number of random permutations, $t$ is the $t$-statistic computed on the observed data, $t_b$ are those computed on the permuted data.

    \vspace{0.2cm}

The test will have power -- i.e., the probability of getting a $p\leq \alpha$ when the two conditions or two samples are really different -- very close to the parametric $t$-statistic, and it will retain control over false positives even when the assumptions of normality are not met.

    \vspace{0.2cm}

It is important to note that the choice of which $t$-statistic to use is a user choice; different test statistics (e.g., difference of mean ranks, Kolmogorov-Smirnov, etc.) will produce tests with different power. For example, if the two samples differ only in their variability and not in their mean, the permutation test based on the $t$-statistic will have little or no power to detect that the two samples come from different populations.
In this direction, the present paper proposes to use the Overlapping Index as a test statistic that results to be powerful under a wide range of differences in distributions.

    \vspace{0.2cm}

{\bf Remark 1} The choice to add a $+1$ in the numerator and denominator is a choice supported by many authors \cite{phipson2010permutation,hemerik2018exact} and ensures that the probability of false positives is less than or equal to $\alpha$.

    \vspace{0.2cm}

{\bf Remark 2} As one can understand, the $p$-value may change depending on the permutations that are drawn. By increasing the number of permutations $B$, the results will change less and less. Since the number of possible permutations is finite, it is preferable, if possible, to explore the set of them (i.e., to compute the statistics on all possible permutations of the data). This set of all possible rearrangements of the data is, in fact, the orbit of the sample that allows us to compute the exact $p$-value - i.e., the exact probability of observing a test statistic that is as extreme or more extreme than that observed in the data. In this case, $B=\binom{n}{n_1} = \frac{n!}{n_1!(n-n_1)!}$ and the $p$-value formula reduces to $$p=\frac{(\#_{b=1}^B |t_b|\geq |t|)}{B}$$ since the test statistic computed on the observed data is certainly in this set.

    \vspace{0.2cm}

\subsection{Application of permutation test to the Overlapping Index}

Even though the Overlapping Index has a simple interpretation, one could argue that it does not provide information on the significance of $\eta$, therefore, we decided to implement permutation testing to offer to the ones interested a value of significance. In particular, we implemented permutation testing, to give a tool that tests differences in distributions without assumptions, offering a valid alternative in cases in which traditional assumptions are not met. 

    \vspace{0.2cm}

If we are reasoning from the perspective of Null Hypothesis Significance Testing (NHST), we should define the null hypothesis as follows: $H_0: \eta = 1$,  meaning that there is complete overlap between the theoretical densities in the two populations from which we sample the data. For this reason, it is more intuitive to work with the complement of $\eta$, which is  $1-\eta = \zeta$ which is the area of non-overlap, therefore, defining the null hypothesis as  $H_0:\zeta = 0$, once again meaning that there is no difference between the densities of the two populations. Obviously, this does not change the results, but only the way in which they are interpreted. When testing the difference between the two distributions, we will no longer be working with $\eta$, but with the complement $\zeta$. 

    \vspace{0.2cm}

The algorithm estimates the value of $\zeta$ on the observed data ($\hat{\zeta}$). Then, through permutation, the observed values of the two groups are randomly re-assigned to the groups for B times, estimating again the new value of  $\hat{\zeta}_b$. The times in which the estimate of $\hat{\zeta}_b$ on permuted data is higher or equal than the one observed on real data is estimated ($\hat{\zeta}_b \geq \hat{\zeta}$) and then the found value is divided by B, returning the $p$-value. 

    \vspace{0.2cm}

\subsection{Illustrative example with real data}

<<echo = FALSE>>=
DATA <- read.csv("EngTurk.csv")

# works with high and low frequency in English
table(DATA$item[DATA$ItemType == "High_freq" & DATA$Language == "English"])
table(DATA$item[DATA$ItemType == "Low_freq" & DATA$Language == "English"])
# blue eyes 
# children

low_frequency <- DATA$ReactionTime[DATA$item == "poor children"]
high_frequency <- DATA$ReactionTime[DATA$item == "blue eyes"]

# Create xList immediately after defining the data
library(datawizard)
library(overlapping)
xList <- list( x1 = low_frequency, x2 = high_frequency ) 

# Compute observed zeta (obsz) and all required statistics
obsz <- 1 - overlap( xList )$OV
MX <- lapply(xList, mean, na.rm=T)
SDX <- lapply(xList, var, na.rm=T)
SKX <- lapply(xList, skewness, na.rm=T)
@


<<permtest2,results='hide',cache=TRUE, echo=FALSE>>=
# Compute permutation values (zperm)
B <- 2e3
n <- length(xList[[1]])
zperm <- sapply(1:B, function(x){
  xperm <- sample(unlist(xList))
  xListperm <- list(x1 = xperm[1:n], x2 = xperm[(n+1):(n*2)])
  1 - overlap(xListperm)$OV
})
@


<<echo=FALSE,cache=TRUE>>=
PVAL <- (sum(zperm > obsz) + 1) / (length(zperm) + 1)
PERMTEST <- perm.test(xList)
TEX <- with(xList, t.test(x1, x2, var.equal = TRUE))
TEXw <- with(xList, t.test(x1, x2))
@

    \vspace{0.2cm}

\textcolor{red}{To show a realistic application and possible workflow we present a real case of a dataset available online \cite{Oksuz_Rebuschat_2024}\footnote[1]{Link to the dataset: https://osf.io/muwjz/files/ubtyq} on reaction times of word reading of high and low frequency words in English. For the applied example we selected two conditions of word reading of high and low frequency words in English of \Sexpr{length(xList$x2)} and \Sexpr{length(xList$x1)} observations respectively.}

    \vspace{0.2cm}


<<ex2,fig.cap=paste0("[A] Distribution of reaction times of word reading of high (blue) and low (red) frequency words in English. The overlapping area is $\\hat{\\eta} = ",round(1-obsz,2),"$, corresponding to a non-overlapping area of $\\hat{\\zeta} = 1 - \\hat{\\eta} = ",round(obsz,2),"$; [B] Distribution of $\\hat{\\zeta}$ obtained with ",B," permutations of the data."),fig.pos="!t", fig.width=6>>=
x1List <- list( x1 = low_frequency, x2 = high_frequency ) 
x1List[[1]] <- c(x1List[[1]], NA)
Y <- stack(data.frame(x1List))
ZPERM <- data.frame(zperm)

theme_set(theme_bw())
cowplot::plot_grid(
  ggplot(Y, aes(values,fill=ind,color=ind)) + 
    geom_density(alpha = .5) + 
    theme(legend.title = element_blank()) + 
    xlab("Reaction Time (seconds)") + 
    ylab("") + 
    guides(fill="none",color="none") + 
    ggtitle("[A]"),

  ggplot(ZPERM, aes(zperm)) + 
    geom_vline(xintercept = obsz, lty=2) + 
    geom_density() + 
    ggtitle("[B]") + 
    xlab(expression(paste(hat(zeta), " distribution"))) + 
    ylab(""), 
  ncol=2
)
@

\subsubsection{Step 1: descriptive statistics and data visualization}

\textcolor{red}{The first step is to plot the two conditions/groups (panel [A] figure \ref{fig:ex2}). This can easily be done with the  \texttt{overlapping} R package  \cite{overlapping:package}. First the user has to upload the package in the R environment, then a list object is created with the two vectors of values of the two groups/conditions, subsequently the function  \texttt{overlap} is used allowing to easily plot densities by setting  \texttt{plot = T}. Here a quick illustration of code:}

<<results='markup'>>=
# upload the package
cat("library( overlapping )","\n")
# create a list with the two vectors of observations
cat("yList <- list( y1 = y1, y2 = y2 )","\n")
# use the funtion overlap
cat("overlap( yList, plot = TRUE )","\n")

@

\textcolor{red}{Simultaneously, calculate descriptive statistics (see table \ref{tab:desc_stats}). The two conditions have means of  \Sexpr{paste(round(unlist(MX),2),collapse = " and ")}, variance of \Sexpr{round(SDX$x1,2)} for both conditions, and skewness of \Sexpr{paste(round(unlist(SKX),2),collapse = " and ")}, for Low and High frequency respectively. The overlapping area between the two distributions is $\eta = \Sexpr{round(1-obsz,2)}$, and consequently $\zeta = 1-\Sexpr{round(1-obsz,2)} = \Sexpr{round(obsz,2)}$. Already from this information, one can have insight on the characteristics of the data.}

<<results='asis', warning=FALSE, message=FALSE>>=
library(moments)
library(xtable)

MNX  <- lapply(xList, mean)
MDX  <- lapply(xList, median)
SDX  <- lapply(xList, var)
SKX  <- lapply(xList, skewness)
KRTX <- lapply(xList, kurtosis)

stats <- data.frame(
  c("Mean", "Median", "Variance", "Skewness", "Kurtosis"),
  c(MNX$x1, MDX$x1, SDX$x1, SKX$x1, KRTX$x1),
  c(MNX$x2, MDX$x2, SDX$x2, SKX$x2, KRTX$x2)
)

colnames(stats) <- c("", "Low frequency", "High frequency")

xt <- xtable(
  stats,
  caption = "Descriptive statistics for low and high frequency words",
  label = "tab:desc_stats"
)

print(
  xt,
  include.rownames = FALSE,
  booktabs = TRUE,
  floating = TRUE,
  caption.placement = "bottom"
)
@


\subsubsection{Step 2: Significance testing}

\textcolor{red}{After visualizing the data and carefully evaluating descriptive statistics, one can move to hypothesis testing. In the case that a global test is appropriate to answer the research question, or it is a case of small sample size and assumptions violation, the performance of a statistical test on the Overlapping Index is appropriate. To perform the $\zeta$-Overlapping test, the procedure is the same as to use the \texttt{overlap} function, with the only difference that the function \texttt{perm.test} is used instead, as shown below:}

<<results='markup'>>=

cat("perm.test( yList )","\n")
cat("","\n")

@
 
\textcolor{red}{The function will give the following output: }
 
<<results='markup'>>=
PERMTEST
@

\textcolor{red}{ \texttt{Zobs} is the observed $\zeta$ and \texttt{pval} is the $p$-value obtained through permutations.}
 
     \vspace{0.2cm}
 
\textcolor{red}{ In figure \ref{fig:ex2}[B] is represented the distribution of the values of $\hat{\zeta}$ obtained with \Sexpr{B} permutations; the $p$-\emph{value} is calculated as follows:}

\begin{eqnarray*}
p = \frac{(\# \hat{\zeta}_b \geq \hat{\zeta})+1 }{B+1} = \frac{\Sexpr{sum( zperm > obsz )+1}}{ \Sexpr{length( zperm )+1} } %= \Sexpr{PVAL}
\end{eqnarray*}

\textcolor{red}{Using the permutations to obtain a $p$-value on $\zeta$, gives a $p < \Sexpr{numeriAPA(round(PERMTEST$pval,2))}$. Based on this test, we can conclude that there is a statistically significant difference between the two distributions, with an area of non-overlap equal to \Sexpr{round(obsz,2)}. Instead, performing a $t$-test gives a non significant result: $t(\Sexpr{TEX$parameter}) = \Sexpr{round(TEX$statistic,2)}$, $p = \Sexpr{numeriAPA(round(TEX$p.value,2))}$. The same result is given by the Welch Test (t-test adjusted for unequal variance) as the two conditions have equal variance.}

    \vspace{0.2cm}

\textcolor{red}{  This result suggests that the overlapping method has detected differences that the previous $t$-tests did not identify, highlighting the potential sensitivity of this approach.}
  
    \vspace{0.2cm}
  
\textcolor{red}{In our example, we believe that no additional testing is needed, as the graphical representation, the descriptive statistics and the $\zeta$-Overlapping test give a clear insight of the difference between the two conditions, with a $\zeta = \Sexpr{round(obsz,2)}$ and a clear delay in reaction time of the Low frequency condition.}

  \vspace{0.2cm}

\textcolor{red}{Similarly, if two groups were not to differ significantly, especially with a small sample, the researcher should have focused on the the effect size and reason if the area of non-overlap could be considered reasonably a trivial difference (based on the field of study and the specific effect) or if more data was needed to reach a meaningful conclusion. One can not simply reject $H_0$ and should carefully evaluate the effect size, as absence of significance does not mean absence of an effect. In this case, reasoning on the smallest effect size of interest (SESOI) and running a sensitivity analysis (ideally a priori power analysis should be run before the data collection) can be beneficial for the researcher. }

  \vspace{0.2cm}

\textcolor{red}{This approach highlights the importance of visualizing data and stresses out the invaluable insight offered by descriptive statistics \cite{wilkinson1999statistical, tay2016graphical, pastore2017one}. However, in case of clear differences raising in Step 1 and confirmed in Step 2, one can decide to move forward with Step 3.}

\subsubsection{Step 3: Tailored parameter specific testing}

\textcolor{red}{This step is optional and should be implemented only if there is a real need for specific parameter testing and should be guided by descriptive statistics and data visualization, in order to avoid type I error inflation (as shown in Supplementary Material). Depending on the research question and data structure, the researcher may include independent samples t-tests (or Welch tests) for evaluating mean differences, Levene’s or F tests for variance comparisons, and skewness or kurtosis assessments (the Kolmogorov-Smirnov test) for shape-related aspects. This layered approach allows researchers to systematically unpack the nature of the difference indicated by the $\zeta$ test, promoting transparency and reducing over-reliance on any single summary statistic.}

  \vspace{0.2cm}

\textcolor{red}{We also believe that Step 2 can be substituted directly by Step 3 if the researcher has a clear parameter specific hypothesis and descriptive statistics support such choice by not showing clear assumptions violation.}


\subsection{The Simulation study}

To evaluate the performance of the permutation test applied to the Overlapping Index, we performed a simulation study. The aim is to generate data for a set of scenarios distinguishing mean, variance and shape of the populations and compare the $\zeta$ perm test to other commonly used tests in terms of type I error control and power. 

\subsection{Data generation}

In the simulation, two density distributions will be compared for many different scenarios. The first distribution will always be a normal standard distribution with $\mu = 0$ and $\sigma = 1$. 
To simulate data for the second distribution we use the Skew-Normal distribution \cite{azzalini:1985}, which is defined in the following way: given $\xi \in \mathbb{R}$, $\omega \in \mathbb{R}^{+}$ and $\alpha \in \mathbb{R}$, then for $y \in \mathbb{R}$ we have  
\begin{equation}
\mathcal{SN}(y|\xi, \omega, \alpha) = \frac{1}{\omega \sqrt{2\pi}} \exp \left[ -\frac{1}{2} \left( \frac{y-\xi}{\omega} \right)^2  \right] \left[ 1+ \text{erf}\left( \alpha \left( \frac{y-\xi}{\omega\sqrt{2}}\right) \right) \right]
\end{equation}
in which $$\text{erf}(z) = \frac{2}{\sqrt{\pi}} \int_{0}^{z} e^{-t^2} dt $$ is the \emph{error function}.
When $\xi = 0$, $\omega = 1$ and $\alpha = 0$ the distribution is a standard normal distribution.

    \vspace{0.2cm}

$\xi$ is the location parameter, $\omega$ is the scale parameter and $\alpha$ is related to the skewness of the distribution. Therefore, this distribution is suitable to generate data modelling both the distance between means (the effect size), symmetry and variance.


\begin{figure*}[!h]
<<scenari,fig.width=7,message=FALSE>>=
library(sn)

PARlist <- list(
  xi_vec = c(0,.5,1),
  omega_vec = c(1,2,3),
  alpha_vec = c(0,1,2)
)

x <- seq(-5,5,by=.1)

gData <- NULL
for (j in 1:3) {
  
  # xi
  y <- with( PARlist, dsn(x,xi_vec[j],omega_vec[1],alpha_vec[1]) )
  xi <- PARlist$xi_vec[j]
  omega <- PARlist$omega_vec[1]
  alpha <- PARlist$alpha_vec[1]
  scenario <- "xi"
  dd <- data.frame(x,y,xi,omega,alpha,scenario)  
  gData <- rbind(gData,dd)  
  
  # omega
  y <- with( PARlist, dsn(x,xi_vec[1],omega_vec[j],alpha_vec[1]) )
  xi <- PARlist$xi_vec[1]
  omega <- PARlist$omega_vec[j]
  alpha <- PARlist$alpha_vec[1]
  scenario <- "omega"
  dd <- data.frame(x,y,xi,omega,alpha,scenario)  
  gData <- rbind(gData,dd)  
   
  # alpha
  y <- with( PARlist, dsn(x,xi_vec[1],omega_vec[1],alpha_vec[j]) )
  xi <- PARlist$xi_vec[1]
  omega <- PARlist$omega_vec[1]
  alpha <- PARlist$alpha_vec[j]
  scenario <- "alpha"
  dd <- data.frame(x,y,xi,omega,alpha,scenario)  
  gData <- rbind(gData,dd)  
  
}

gData$xi <- factor(gData$xi)
gData$omega <- factor(gData$omega)
gData$alpha <- factor(gData$alpha)

UNIT <- .5

theme_set(theme_bw())
cowplot::plot_grid(
  ggplot(subset(gData,scenario=="xi"),aes(x,y,color=xi)) + 
    geom_line() + 
    xlab("") + 
    ylab("") + 
    ggtitle("[A]") + 
    labs(color=expression(xi)) + 
    theme(legend.position = "bottom", legend.key.size = unit(UNIT,"cm")),
  
  ggplot(subset(gData,scenario=="omega"),aes(x,y,color=omega)) + 
    geom_line() + 
    xlab("") + 
    ylab("") + 
    ggtitle("[B]") + 
    labs(color=expression(omega)) + 
    theme(legend.position = "bottom", legend.key.size = unit(UNIT,"cm")),
  
  ggplot(subset(gData,scenario=="alpha"),aes(x,y,color=alpha)) + 
    geom_line() + 
    xlab("") + 
    ylab("") + 
    ggtitle("[C]") + 
    labs(color=expression(alpha)) + 
    theme(legend.position = "bottom", legend.key.size = unit(UNIT,"cm")), 
  nrow = 1
)
@
\caption{Examples of Skew-Normal distributions ($\xi$,$\omega$,$\alpha$); [A] three densities with same scale and shape but different location parameter values ($\xi = \Sexpr{PARlist$xi_vec}$), [B] three densities with same location and shape but different scale parameter values ($\omega = \Sexpr{PARlist$omega_vec}$) and [C] three densities with same location and scale but different shape parameter values ($\alpha = \Sexpr{PARlist$alpha_vec}$). \label{fig:scenari}}
\end{figure*}

    \vspace{0.2cm}

Mean and variance of the Skew-Normal are respectively: 
\begin{eqnarray}\label{eq:musigmaSN}
\begin{array}{l}
\mu = \xi + \omega \gamma \sqrt{2/\pi} \\
\sigma^2 = \omega^2 [1- (2\gamma^2)/\pi]
\end{array}
\end{eqnarray}
in which $\gamma = \alpha / \sqrt{1 + \alpha^2}$. Based on the equations (\ref{eq:musigmaSN}) we can determine the values to assign to the parameters $\xi$ e $\omega$ in function of $\mu$ and $\sigma$ with the equations:

\begin{eqnarray}\label{eq:xiomegaSN}
\begin{array}{l}
 \xi = \mu - \omega \gamma \sqrt{2/\pi} \\
 \omega = \sqrt{\sigma^2/ [1- (2\gamma^2)/\pi]}
\end{array}
\end{eqnarray}

The Skew-Normal distribution is optimal for our purpose as it allows to have control over parameters of mean, variance, skewness and kurtosis, as shown in figure \ref{fig:scenari}.

\subsection{Simulation design}

<<cache=FALSE>>=
load("R02_sim07.rda")
NTAB <- table(ALL$n,ALL$mu,ALL$sigma,ALL$alpha)
@


In the simulation we confront two samples extracted from a Skew-Normal, the first one is generated from $\mathcal{SN}(0,1,0)$, which is the Standard-Normal distribution, and the second one from $\mathcal{SN}(\xi,\omega,\alpha)$. Consequently, the first sample derives always from a population with mean 0 and variance 1. To define the various scenarios, we manipulate the parameters of the second population in orther to obtain specific differences in means ($\delta$), standard deviations ($\sigma$) and skewness ($\alpha$). Four factors were sistematically varied in a complete four-factors design as follows:

\begin{itemize}

   \item $\delta = (\Sexpr{PARlist$mu_vec})$; mean of the second population, which corresponds also to the difference between the two groups, the first one has always $\mu = 0$;
  \item $\sigma = (\Sexpr{PARlist$sigma_vec})$; standard deviation of the second population;
  \item $\alpha = (\Sexpr{PARlist$alpha_vec})$; degree of asymmetry (skewness) of the second population; 
  \item $n = (\Sexpr{PARlist$n_vec})$; sample size, equal in the two samples.
 
  %\item N simulation: \Sexpr{NTAB[1,1,1,1]} for each combination of parameters

\end{itemize}


For each of the $\Sexpr{length(PARlist$mu_vec)} \times \Sexpr{length(PARlist$sigma_vec)} \times \Sexpr{length(PARlist$alpha_vec)} \times \Sexpr{length(PARlist$n_vec)} = \Sexpr{length(PARlist$n_vec)*length(PARlist$mu_vec)*length(PARlist$sigma_vec)*length(PARlist$alpha_vec)}$ conditions we generated \Sexpr{NTAB[1,1,1,1]} sets of data on which we performed the analysis. 


<<message=FALSE>>=

INDICI <- colnames(ALL)[grep("pval",colnames(ALL))]
INDICI <- INDICI[!(grepl("_norm",INDICI)|grepl("F_",INDICI)|grepl("mean_",INDICI))]
INDICI <- INDICI [c(1:3, 6, 4, 5)]

LEGENDA <- data.frame( var = colnames(ALL), desc = c("media camp. 1", "sd camp. 1","media camp. 2", "sd camp. 2", "overlapping tipo 1", "overlapping tipo 2", "sample size","differenza tra le xi","skewness","varianza","vera sovrapposizione","t test","welch test","wilcoxon test", "var test", "overlapping perm","mean perm", "var perm", "shapiro camp. 1", "shapiro camp. 2","kolmogorov","media secondo campione","ds secondo campione") )

MUSI <- with( PARlist, expand.grid(mu=mu_vec, sigma=sigma_vec, alpha = alpha_vec) )

DESIGN <- NULL 
for (i in 1:nrow(MUSI)) {
  DESIGN <- rbind( DESIGN, unlist( with( MUSI, sninvpar(mu[i],sigma[i],alpha = alpha[i]) )) )
}

DESIGN <- data.frame(DESIGN)
DD <- with( DESIGN, expand.grid( xi = unique(xi), omega = unique(omega), 
              alpha = unique(alpha), n = PARlist$n_vec ) )
DESIGN <- apply(DD, 1, as.list)

DD <- do.call(rbind,lapply(DESIGN, function(x){
  unlist(x)
}))
DD <- data.frame( unique( DD[,c("xi","omega","alpha")] ) )
DD$mu <- factor(with(DD, snpar(xi,omega,alpha)$mu))
DD$sigma <- factor(with(DD, snpar(xi,omega,alpha)$sigma))

DD <- subset( DD, (mu %in% PARlist$mu_vec)  & (alpha %in% PARlist$alpha_vec ) & (sigma %in% PARlist$sigma_vec))

@



<<message=FALSE>>=
library(brms)

x <- seq(-5,5, by=.01)
gData <- data.frame(x=x)
gData$z <- dskew_normal(x,xi=0,omega=1)

for (i in 1:nrow(DD)) {
  k <- with(DD, paste0("mu_",mu[i],"_sigma_",sigma[i],"_alpha_",alpha[i]))
  y <- dsn( gData$x, xi = DD$xi[i], omega = DD$omega[i], alpha = DD$alpha[i] )
  
  gData <- cbind(gData,y)
  colnames(gData)[ncol(gData)] <- k
  
}

Y <- stack( gData[,grep("mu",colnames(gData))] )
Y$x <- gData$x
Y$z <- gData$z

ll <- strsplit(as.character(Y$ind),split="_")

Y$mu <- factor( unlist( lapply(ll, function(x){x[2]}) ))
Y$sigma <- factor( unlist( lapply(ll, function(x){x[4]}) ))
Y$alpha <- factor( unlist( lapply(ll, function(x){x[6]}) ), levels = c(0,2,10))

TEXT <- unique(Y[,c("mu","sigma","alpha")])
TEXT$label <- paste0("[",1:36,"]")
TEXT$x <- -4.5
TEXT$y <- .4

@

\begin{figure*}
%,fig.width=7,fig.cap=" ",fig.height=9
<<alpha0,fig.width=7,fig.height=9>>=

theme_set(theme_bw())
ggplot(Y,aes(x,z)) + facet_grid(alpha+sigma~mu) + geom_line() + geom_line(aes(x,values,color="red")) + geom_text( aes(x,y,label=label), data = TEXT) + guides(color="none") + xlab("") + ylab("") + scale_y_continuous(breaks = NULL)

@
\caption{Generative data distributions in function of $\delta$ (column panels),  $\sigma$ and $\alpha$ (row panels). The black curves are the first population, $\mathcal{SN}(0,1,0)$, the red ones represent second population, $\mathcal{SN}(\xi,\omega,\alpha)$.\label{fig:alpha0}}
\end{figure*}

In figure \ref{fig:alpha0} are graphically represented the 36 scenarios of data generation, the black curves are the first population, always a $\mathcal{SN}(0,1,0)$, and the red curves are relative to the second population $\mathcal{SN}(\xi,\omega,\alpha)$.

    \vspace{0.2cm}

For each combination $\delta \times \sigma \times \alpha \times n $, on the generated data were performed the following tests: 
\begin{itemize}
 \item $t$ test for independent samples, assuming equal variance;
 \item Welch test for independent samples;
 \item Wilcoxon test for independent samples;
 \item Permutation test on the complement of the Overlapping Index, $\zeta = 1-\eta$, which therefore becomes an index of difference between groups;
 \item $F$ test of homogeneity of variances;
 \item Kolmogorov-Smirnov test for comparing two distributions.
\end{itemize}

The whole procedure generated a total of \Sexpr{nrow(ALL)} datasets as well as \Sexpr{as.character(nrow(ALL)*6)} of statistical tests and corresponding $p$-values.



\subsection{Definition of Statistical tests}

We introduce the chosen statistical tests summarizing the specific hypothesis and assumptions for each one. 

\subsubsection{$t$ test}

This is the classic case of a test for independent samples assuming equal variances and the normality of the two distributions:
 
\begin{eqnarray*}
H_0: \mu_1 - \mu_2 = 0 \mbox{ with } \sigma^2_1 = \sigma^2_2
\end{eqnarray*}

\textcolor{red}{Therefore, in the scenarios from which the samples come from populations with same mean -- figure \ref{fig:alpha0}, panels in the first left column, [1, 5, 9, 13, 17, 21, 25, 29, 33] -- type I error control is estimated, meanwhile, power is estimated for the remaining scenarios. Note that assumption of homogeneity of variance for this test are met only in the scenarios in the first row.}

\subsubsection{Welch (W) test}

This is the $t$ test modified when homogeneity of variances is not respected:

\begin{eqnarray*}
H_0: \mu_1 - \mu_2 = 0 \mbox{ with } \sigma^2_1 \neq \sigma^2_2
\end{eqnarray*}

Also this test assumes the normality.

\textcolor{red}{Control of type I error is estimated for the same scenarios as for the $t$ test, as well as for the power.}

\subsubsection{Wilcoxon-Mann-Whitney (WMW) test}

This is the test on ranks which evaluates the following hypothesis without assumptions on distributions:
 
\begin{eqnarray*}
H_0: P(X_1 > X_2) = P(X_2 > X_1) = 0.5
\end{eqnarray*} 

in which $X_1$ and $X_2$ are the random variables representing the observations extracted from the two populations. \textcolor{red}{In this case, the only scenario in which $H_0$ is true is in panel [1]. Given that this is a distribution free test, assumptions are not required.}

\subsubsection{Kolmogorov-Smirnov (KS) test}

This test compares the cumulative distributions $$H_0: F(X_1) = F(X_2)$$ without assumptions on distributions. \textcolor{red}{The null hypothesis is true in panel [1], as it is for the  $\zeta$  permutation test.}

\subsubsection{$F$ test}

This is the test of homogeneity of variances $$H_0: \sigma^2_1 = \sigma^2_2$$ assuming the normality. \textcolor{red}{The condition is true in all scenarios where $\sigma = 1$, panels [1-4, 13-16, 25-28]. In those scenarios we estimate type I error, in all the others we calculate power.}

\subsubsection{ $\zeta$-Overlapping ($\zeta_{\mbox{ov}}$) test}

Since $\zeta = 1 - \eta$, in which $\eta$ is the area of overlapping of the empirical distributions, the null hypothesis of the test is $$H_0: \zeta = 0$$ which implies that the data comes from the same population, or from populations with same shape (mean, variance and skewness) but without specific assumptions. \textcolor{red}{Therefore, the only condition in which $H_0$ is true is the first panel, [1]. Also in this case, the test does not require particular assumptions.}

\section{Results}

First of all, we analysed correlations between the $p$-values of the considered tests in order to assess how much they are associated independently from the experimental condition. Next, we considered separately for each test in which scenarios $H_0$ is true, as reported in the previous section. Consequently, we computed type I error by counting how many times the test is significant in those scenarios, and the power by counting how many times it will be significant in all other scenarios. In this way, we evaluated type I error and power based on the experimental conditions.


\subsection{Correlations among tests}

Figure \ref{fig:correlazioni} represents the correlation matrix between the $p$-values for the different tests in all experimental conditions. The classical tests show an order in the way they correlate. More specifically, $t$ and W tests show a perfect correlation, WMW is highly correlated with the aforesaid tests, and the KS shows a lower but still medium-large correlation. $F$ presents no correlation with $t$, W and WMW tests, and medium correlation with the $\zeta_{\mbox{ov}}$ and KS tests. 

  \vspace{0.2cm}

The $\zeta_{\mbox{ov}}$ test is highly correlated with the KS test, has a lower correlation with tests on means ($t$ and W) and ranks (WMW), and a medium correlation with the $F$ test.

\textcolor{red}{The lower correlations observed among the test statistics are expected, given that each test is designed to detect different aspects of the data - whether central tendency, variance, or overall distributional shape. This pattern reinforces the idea that tests are not interchangeable but rather complementary in what they capture. The $\zeta$-Overlapping test, by design, integrates sensitivity to multiple features, which may explain its lower correlations with more narrowly focused tests. Therefore, while the correlation matrix does not offer direct interpretive insight into test performance, it supports the broader claim that distinct tests yield distinct inferential perspectives.}

<<>>=
SAMPLE_prop <- .005
ALL0 <- subset(ALL,alpha == 0 )
righe <- sample(1:nrow(ALL0),nrow(ALL0)*SAMPLE_prop)
ALL2 <- subset(ALL,alpha == 2)
ALL10 <- subset(ALL,alpha == 10)
@

<<correlazioni,fig.cap=paste0("Correlation matrix among $p$-values $(N = ",nrow(ALL),")$ in chosen tests. Note: $\\zeta_{\\mbox{ov}}$ = $\\zeta$  overlapping test, $F$ = variance test, ks = Kolmogorov-Smirnov test, wmw = Wicoxon-Mann-Whitney test, w = Welch test, $t$ = Student's $t$ test."),fig.pos="!t",fig.width=4, message=FALSE>>=
options(digits = 10)
RR <- cor(ALL[,INDICI])

colnames(RR) <- rownames(RR) <- gsub("welch","w",
                                     gsub("ks_test","ks",
                                     gsub("vartest","F",
                                     gsub("wilcox","wmw",
                                     gsub("zeta_perm","zeta_ov",
                                     gsub("_pval","",rownames(RR)))))))


colnames(RR)[1] <- rownames(RR)[1] <- "t"

RR[1,2] <- RR[2,1] <- .99

plot_correlation(RR, textsize = 13, angle = 0, values = TRUE, corrsize = 3.5, 
                 U = c(-2,0,-3,-.5), legendsize = 11)
@


\subsection{Type I error and power}

<<>>=
ALL$zeta_perm_sig <- ifelse(ALL$zeta_perm_pval<=.05,TRUE,FALSE)
ALL$t_pval_sig <- ifelse(ALL$t_pval <= .05, TRUE, FALSE)
ALL$welch_pval_sig <- ifelse(ALL$welch_pval <= .05, TRUE, FALSE)
ALL$wilcox_pval_sig <- ifelse(ALL$wilcox_pval <= .05, TRUE, FALSE)
ALL$vartest_pval_sig <- ifelse(ALL$vartest_pval <= .05, TRUE, FALSE)
ALL$ks_test_pval_sig <- ifelse(ALL$ks_test_pval <= .05, TRUE, FALSE)

ALL$zeta_perm_H0_true <- with(ALL, ifelse(mu==0 & sigma == 1 & alpha == 0, TRUE, FALSE))
ALL$t_H0_true <- with(ALL, ifelse(mu==0, TRUE, FALSE))
ALL$welch_H0_true <- with(ALL, ifelse(mu==0, TRUE, FALSE))
ALL$wilcox_H0_true <- with(ALL, ifelse(mu==0 & sigma == 1 & alpha == 0, TRUE, FALSE))
ALL$vartest_H0_true <- with(ALL, ifelse(sigma == 1, TRUE, FALSE))
ALL$ks_H0_true <- with(ALL, ifelse(mu==0 & sigma == 1 & alpha == 0, TRUE, FALSE))




@

<<>>=
PW <- aggregate( zeta_perm_sig ~ n+zeta_perm_H0_true, data = ALL, FUN = mean)
PW$t_sig <- aggregate( t_pval_sig ~ n+t_H0_true, data = ALL, FUN = mean)$t_pval_sig
PW$welch_sig <- aggregate( welch_pval_sig ~ n+welch_H0_true, data = ALL, FUN = mean)$welch_pval_sig
PW$wilcox_sig <- aggregate( wilcox_pval_sig ~ n+wilcox_H0_true, data = ALL, FUN = mean)$wilcox_pval_sig
PW$vartest_sig <- aggregate( vartest_pval_sig ~ n+vartest_H0_true, data = ALL, FUN = mean)$vartest_pval_sig
PW$ks_sig <- aggregate( ks_test_pval_sig ~ n+ks_H0_true, data = ALL, FUN = mean)$ks_test_pval_sig

Y <- stack(PW[,grep("_sig",colnames(PW))])
Y$H0 <- PW$zeta_perm_H0_true
Y$n <- PW$n
@

In figure \ref{fig:global}, is represented type I error in panel [A] and power in panel [B] estimated considering\textcolor{red}{ as true null hypothesis the situations reported in the section \textit{Definition of Statistical tests}.}

  \vspace{0.2cm}

In relation to type I error, almost all tests show a good performance, whereas the KS test is too conservative for small samples \textcolor{red}{and the $F$-test is always above the nominal level of $0.05$ (even with 500 observations per group). }

  \vspace{0.2cm}

\textcolor{red}{Concerning power, the $\zeta$-Overlapping test is the second outperforming other tests with good control of Type I error, already with small sample sizes, with the only exception of the $F$-test which has higher power but bad control of Type I error}. From the graphical representation it is visible how two subgroups can be identified: one including the tests on means and ranks, not reaching adequate power even with large samples, and the second one formed by the $\zeta_{\mbox{ov}}$ and KS tests, reaching good power already from 100 observations, with the $\zeta_{\mbox{ov}}$ outperforming the KS test reaching good power already from 50 observations. \textcolor{red}{\textbf{Remark} It is important to note that the six tests compared in this simulation evaluate different null hypotheses and are therefore sensitive to different aspects of distributional differences. Specifically: the $\zeta$-Overlapping test evaluates $H_0: \zeta = 0$ (complete distributional overlap); the $F$-test evaluates $H_0: \sigma^2_1 = \sigma^2_2$ (homoscedasticity); the Kolmogorov-Smirnov test evaluates $H_0: F(X_1) = F(X_2)$ (identical cumulative distribution functions); the Wilcoxon-Mann-Whitney test evaluates $H_0: P(X_1 > X_2) = 0.5$ (stochastic equality); the Welch test evaluates $H_0: \mu_1 = \mu_2$ allowing unequal variances; and the Student's $t$-test evaluates $H_0: \mu_1 = \mu_2$ assuming equal variances. The observed differences in Type I error control and power directly reflect these different inferential targets: tests targeting specific parameters (e.g., means or variances) will naturally show lower power when the true difference lies in other distributional features, while global tests like $\zeta_{ov}$ and KS are sensitive to a broader range of distributional deviations.}


\begin{figure*}[!h]
<<global,fig.width=7>>=

levels(Y$ind) <- gsub("zeta","zeta",
                     gsub("welch","w",
                     gsub("vartest","F",
                     gsub("wilcox","wmw",
                     gsub("_perm","_ov",
                     gsub("_sig","",levels(Y$ind)))))))

Y$ind <- factor(Y$ind, levels=levels(Y$ind)[c(1,5:6,4:2)])

theme_set(theme_bw())
plot_grid(
  ggplot(subset(Y,H0==TRUE), aes(n,values,color=ind,shape=ind)) + 
    geom_hline(yintercept = .05, lty = 3) + 
    geom_line() + 
    geom_point() + 
    guides(color="none",shape = "none") + 
    ggtitle(expression(paste("[A] ", H[0], " true"))) + 
    ylab(expression(paste("P(reject ", H[0], ")"))) + 
    xlab("sample size (per group)"),
  
  ggplot(subset(Y,H0==FALSE), aes(n,values,color=ind,shape=ind)) + 
    geom_hline(yintercept = .05, lty = 3) + 
    geom_line() + 
    geom_point() + 
    theme(legend.title = element_blank()) + 
    ggtitle(expression(paste("[B] ", H[0], " false"))) + 
    ylab(expression(paste("P(reject ", H[0], ")"))) + 
    xlab("sample size (per group)"),
  
  rel_widths = c(.6,1)
)
@
\caption{Control of type I error [A] and power [B] in the various tests. Note: $\zeta_{\mbox{ov}}$ = $\zeta$-Overlapping test, $F$ = variance test, ks = Kolmogorov-Smirnov test, wmw = Wicoxon-Mann-Whitney test, w = Welch test, $t$ = Student's $t$ test. \label{fig:global}}
\end{figure*}



\section{Discussion}

The analysis of $p$-value correlations among the tests provides insight into their relationships. High correlation between the $t$-test and W test, for instance, reflects their similar objectives and shared focus on mean differences. However, lower correlations between parametric and non-parametric methods, such as the WMW and KS tests, indicate that these tests capture distinct aspects of the data, such as ranks or distribution shapes rather than means. The permutation-based tests show intermediate correlations with both parametric and non-parametric methods, which suggests that they may align with either types of tests depending on the underlying data structure, highlighting the versatility of the $\zeta_{\mbox{ov}}$ test.

  \vspace{0.2cm}

Moreover, the present analysis evaluated the performance of various statistical significance tests across simulated scenarios comparing each test on the appropriate null hypothesis. The tests include both parametric (such as the $t$-test, Welch test, and $F$-test for variance) and non-parametric methods (such as the Wilcoxon Signed-Rank, Kolmogorov-Smirnov, and permutation-based approaches including the $\zeta_{\mbox{ov}}$ test). Through these scenarios, we assess each test's Type I error control, and power.


  \vspace{0.2cm}

In figure \ref{fig:global}, panel [A], the only test which is over-conservative in terms of Type I error is the KS test, yet reaching the nominal $.05$ level with bigger samples (over 400 observations). Instead, the $F$-test shows a bad control of Type I error, always exceeding the nominal level even with big sample size. All other tests, already from small samples, are in the range of $.045 - .055$, converging closer to $.05$ as sample size grows. From this analysis we can then conclude that most of the tests sufficiently control the Type I error, but caution is needed for the $F$-test even with big samples and with the KS test with small samples. \textcolor{red}{ Under ideal conditions, when normality and homogeneity of variance hold, the F test performs extremely well and can be highly powerful (see Supplementary Materials for assumption-compliant scenarios). In contrast, when these assumptions are not met, as in the majority of simulated conditions, its Type I error becomes inflated and inference unreliable. This contrast highlights how critically the validity of conclusions depends on assumption checking, making their consideration a central methodological issue rather than a technical detail. This emphasizes that assumption validity is not merely theoretical but decisively shapes inferential outcomes.}

  \vspace{0.2cm}

\textcolor{red}{Concerning power, figure \ref{fig:global} panel [B], the $F$-test is the most sensitive even with small variance differences, at the cost of not controlling Type I error. Second for power is the $\zeta_{\mbox{ov}}$ test outperforms all other tests. Competing with good power is the KS test, reaching a power of 60\% with 50 observations and aligning with the $\zeta_{\mbox{ov}}$ at 500 observations.} W and $t$ tests performances are identical, in line with their almost perfect correlation of $p$-values, never exceeding 60\% of power and performing consistently worse than the $\zeta_{\mbox{ov}}$ and KS tests, especially with small samples. Lastly, the WMW test performs similarly to $t$ and W tests with slightly less power throughout the increase of sample size. These results highlight the outstanding performance of the $\zeta_{\mbox{ov}}$ test already from small samples, showing an advantage in choosing this test in research settings regardless of data distribution and assumptions.

  \vspace{0.2cm}


\textcolor{red}{While the $\zeta$-Overlapping test demonstrates consistently high power across the simulation scenarios, it is not designed to replace traditional tests focused on specific parameters like the mean. Rather, it offers a global option when researchers are not interested in a single parameter, or when data violate the assumptions of parametric tests. In this way, it complements rather than competes with existing approaches, and supports the growing shift in psychological science toward robust, distribution-aware inference.}

  \vspace{0.2cm}

\textcolor{red}{Moreover, it is important to note that this performance reflects its broader sensitivity to differences in distributional shape, not just central tendency therefore it may detect effects that more narrowly focused tests (e.g., t-test or F-test) are not designed to identify. This feature is highlighted in the example presented in the Practical Application section, showing how the $\zeta$-Overlapping test is responsive to a wider set of deviations from the null.}

\subsection*{Limitations of the Present work}

\textcolor{red}{The main limitation of the study is that it simulates only scenarios in which the first population is a Standard-Normal distribution ($\mathcal{SN}(0,1,0)$) and it does not consider the presence of outliers, which would give more insight into the performance of the $\zeta$-Overlapping test. Another concern could be that the test does not inform on specific parametric differences, as its design focuses on distributional overlap rather than mean differences, which means it does not directly inform on mean, variance or skewness differences specifically. But we argue that this is rather a chore caracteristic of the test and not a limitation. The $\zeta_{\mbox{ov}}$ test offers a great starting point to evaluate whether two distributions differ in the first place with high power already from small samples. Moreover, the \texttt{overlapping} R package to easily compute the index also offers the possibility to plot densities and the area of overlap, therefore making it extremely intuitive to visualize how the two distributions practically differ. }

  \vspace{0.2cm}

\textcolor{red}{While the $\zeta$-test offers a broader diagnostic scope, it is not intended to replace targeted hypothesis tests when those are clearly aligned with the research goal and respect the nature of the data. When the research hypothesis specifically targets a single parameter, such as a mean difference, the use of more focused tests (e.g., Welch’s t-test) may offer higher statistical power under valid assumptions. A complementary simulation study comparing power across such focused and omnibus approaches would be a valuable avenue for future work.}

AGGIUNGERE INFO SU BANDWIDTH E LIMITI DA TENERE IN CONSIDERAZIONE QUANDO SI HANNO TANTISSIME OSSERVAZIONI (?)


\section{Conclusion}

\textcolor{red}{Many researchers focus on differences in means and may not initially consider the full distribution of their data. One of the strengths of the $\zeta$-Overlapping test is precisely that it encourages a more holistic view, prompting researchers to explore whether groups differ not just in central tendency but in dispersion or shape as well. More precisely, it is easy to interpret as an effect size, with high values of $\zeta$ signaling differences between the two empirical distributions and low values indicating similarity. It is robust to distributional assumptions, as it calculates $p$-values through permutations rather than relying on parametric assumptions like normality or equal variance, making it particularly useful in scenarios where other tests may be sub-optimal due to assumption violations, also providing a conservative Type I error rate when \(H_0\) is true and robust power when \(H_0\) is false. In practice, the $\zeta$-Overlapping test can serve as a global test that prompts a broader examination of the data’s characteristics.}

  \vspace{0.2cm}

By exploring alternative scenarios, the study offers a practical indication to operate a shift in the philosophical approach to data analysis and significance testing. In fact, the Overlapping Index forces the functional interpretation of the results to move beyond significance testing alone \cite{ steegen2016increasing, gelman2018failure,pastore2019measuring}. In psychological research, considering the distribution of data rather than relying solely on significance testing offers a deeper, more nuanced understanding of results. Traditional significance testing does not provide information about the nature or magnitude of that effect \cite<see>{cohen1994earth, wagenmakers2007practical, ziliak2011cult, wasserstein2016asa}. By visualizing and considering the entire distribution of data, researchers can observe the spread, central tendency, and shape of the data, which often reveal valuable insight about variability and individual differences within the sample.  As in example presented in figure \ref{fig:ex2}, reporting a mean difference without an understanding of the data's distribution could lead to misrepresentation of the consistency or generalizability of the observed effect. Therefore, incorporating distributional analyses allows psychologists to present a fuller picture of their findings, improving both interpretability and transparency in their research conclusions. 

  \vspace{0.2cm}

\textcolor{red}{While classical concerns regarding normality and homoscedasticity tend to diminish with increasing sample sizes, the $\zeta$-Overlapping test offers unique advantages that persist even in large-sample scenarios. Specifically, it provides a formal and assumption-free way to test whether full empirical distributions differ beyond just location parameters allowing researchers to assess global differences with one test. The permutation-based $p$-value offers a rigorous statistical complement to data visualization: while plotting distributions is essential, $\zeta$ offers an objective inferential check that enhances transparency and reproducibility, particularly when interpretation may be ambiguous.}

  \vspace{0.2cm}

\textcolor{red}{Importantly, not all issues resolve with large sample sizes. Psychological measures such as reaction times and even-related potentials (ERPs) components typically exhibit non-normal, right-skewed distributions (Blanca et al., 2013; Ryu, 2011). Reaction-time modeling relies heavily on ex-Gaussian distributions (e.g., Lacouture \& Cousineau, 2008; Spangler et al., 2021) because skew violates parametric test assumptions even with $n > 50$. Meta-analyses show that only $\sim$ 5.5 \% of behavioral datasets approximate normality (skew $\approx$ 0; kurtosis $\approx$ 0), even in moderate sample sizes (n $10 – 30$). These issues are compounded in physiological measures like ERPs, which often follow heavy-tailed distributions due to individual differences and noise. In these contexts, the Overlapping Index $\eta$ and the $\zeta$ test offers a robust, nonparametric alternative: it quantifies full distributional differences and provides $p$-values via permutation, without requiring normality or equal variances. Moreover, beyond traditional significance testing, the $\zeta$-Overlapping framework can be readily adapted for equivalence testing and minimum-effect testing, in line with current recommendations (Murphy \& Myors, 1999; Lakens et al., 2018; Riesthuis, 2024). Because $\eta$ (and its complement $\zeta$) directly quantify the similarity or difference between empirical distributions, researchers can define meaningful thresholds (e.g., $\eta \geq 0.90$ or $\zeta \leq 0.10$) that reflect negligible differences for practical purposes. A permutation-based test of equivalence can then assess whether the observed $\zeta$ falls within the predefined bounds, supporting equivalence. Conversely, a minimum-effect test can assess whether $\zeta$ significantly exceeds a lower threshold, indicating a difference of at least a meaningful size. These extensions preserve the nonparametric and assumption-free nature of the $\zeta$-test while allowing for more nuanced and informative inferential conclusions.}

  \vspace{0.2cm}

Moreover, the present study further underscores the necessity of reasoning on the most suitable statistical tools contingent on the specific characteristics of the data and the assumptions inherent in the analytical techniques employed. Such a switch in the philosophical approach to data analysis in psychological sciences \cite{vasishth2021embrace} may improve the robustness and validity of psychological research findings, allowing for more aware interpretations and generalizations. We stress this by making open available data and material so that such an approach might be useful for a wide range of psychologists interested in increasing the understandability of their results. 

  \vspace{0.2cm}

Ultimately, statistics in psychology should reflect both theoretical knowledge and an appreciation for the distributional nuances of psychological variables. Rather than a rigid application of conventional methods, statistical analysis should be a deliberate choice that aligns with the nature of the data and the research question. The approach of the $\zeta$-Overlapping test embodies this principle, capturing the depth and complexity of psychological effects in a way that is both methodologically rigorous and sensitive to the real-world structure of psychological phenomena.



\subsection*{Legenda}

$\eta$ is the area of overlap

\noindent $\zeta$ is the area of non overlap, therefore $1 - \eta$

\noindent $\mu$ is the parameter of the mean of the normal standard 

\noindent $\sigma$ is the standard deviation of the normal standard

\noindent $\delta$ is the difference between the two means

\noindent $\xi$ is the location parameter of the skew-normal

\noindent $\omega$ is the scale parameter of the skew-normal

\noindent $\alpha$ is the shape parameter of the skew-normal

\subsection*{Funding}
No Funding supported this project.

\subsection*{Conflicts of interest}
The authors declare no conflict of interests.

\subsection*{Ethics approval}
Not applicable.

\subsection*{Consent to practice}
Not applicable.

\subsection*{Consent for pubblication}
Not applicable.

\subsection*{Availability of data and materials}
Data and materials to reproduce the present work are openly available at \href{https://osf.io/3jwsh/?view_only=37ba668675d5425a8681fe3b686c8507}{OSF}


\subsection*{Code availability}
The code to reproduce the present work is openly available at \href{https://osf.io/3jwsh/?view_only=37ba668675d5425a8681fe3b686c8507}{OSF}

\subsection*{Authors' contributions}
All authors contributed substantially to the conceptualization, code development and refinement of this manuscript. X. XXX and X. XXX performed the primary writing task with substantial input from the other authors.


\bibliographystyle{apacite}
\bibliography{overlap}
\end{document}



\bibliographystyle{apacite}
\bibliography{overlap}





